# Robot MCP - Examples

Common use cases and example workflows for robot control with natural language.

## Table of Contents

- [Quick Start Examples](#quick-start-examples)
- [Basic Operations](#basic-operations)
- [Object Manipulation](#object-manipulation)
- [Spatial Reasoning](#spatial-reasoning)
- [Complex Workflows](#complex-workflows)
- [Advanced Patterns](#advanced-patterns)
- [Tips and Best Practices](#tips-and-best-practices)

---

## Quick Start Examples

### Example 1: Hello Robot

```
You: What objects do you see?

ðŸ”§ Calling tool: get_detected_objects
âœ“ Result: Detected 3 objects:
   - pencil at [0.15, -0.05]
   - red cube at [0.20, 0.10]
   - pen at [0.18, -0.03]

ðŸ¤– Assistant: I can see 3 objects: a pencil at [0.15, -0.05],
   a red cube at [0.20, 0.10], and a pen at [0.18, -0.03]
```

---

### Example 2: Simple Pick and Place

```
You: Pick up the pencil and place it at [0.2, 0.1]

ðŸ”§ Calling tool: get_detected_objects
âœ“ Result: Detected objects...

ðŸ”§ Calling tool: pick_place_object
   Arguments: {
     "object_name": "pencil",
     "pick_coordinate": [0.15, -0.05],
     "place_coordinate": [0.2, 0.1],
     "location": "none"
   }
âœ“ Result: Successfully picked and placed

ðŸ¤– Assistant: Done! I've picked up the pencil from [0.15, -0.05]
   and placed it at [0.2, 0.1].
```

---

### Example 3: Relative Placement

```
You: Move the pencil to the right of the red cube

ðŸ”§ Calling tool: get_detected_objects
âœ“ Result: Found pencil and red cube

ðŸ”§ Calling tool: pick_place_object
   Arguments: {
     "object_name": "pencil",
     "pick_coordinate": [0.15, -0.05],
     "place_coordinate": [0.20, 0.10],
     "location": "right next to"
   }
âœ“ Result: Successfully placed

ðŸ¤– Assistant: Perfect! I've moved the pencil to the right of
   the red cube.
```

---

## Basic Operations

### Workspace Scan

```
You: Scan the workspace and tell me everything you see

ðŸ”§ Calling tool: move2observation_pose("niryo_ws")
âœ“ Result: Moved to observation pose

ðŸ”§ Calling tool: get_detected_objects
âœ“ Result: Detected 4 objects...

ðŸ¤– Assistant: I can see 4 objects in the workspace:

   1. Pencil at [0.15, -0.05]
      Size: 1.5cm Ã— 12cm (area: 18 cmÂ²)

   2. Red cube at [0.20, 0.10]
      Size: 4cm Ã— 4cm (area: 16 cmÂ²)

   3. Pen at [0.18, -0.03]
      Size: 1.2cm Ã— 14cm (area: 16.8 cmÂ²)

   4. Blue square at [0.18, -0.10]
      Size: 5cm Ã— 5cm (area: 25 cmÂ²)
```

---

### Find Specific Objects

```
You: Where is the pencil?

ðŸ”§ Calling tool: get_detected_objects(label="pencil")
âœ“ Result: Found pencil at [0.15, -0.05]

ðŸ¤– Assistant: The pencil is located at coordinates [0.15, -0.05].
```

```
You: Which object is the largest?

ðŸ”§ Calling tool: get_largest_detected_object
âœ“ Result: {
  "label": "blue square",
  "position": {"x": 0.18, "y": -0.10},
  "size": {"area_cm2": 25.0}
}

ðŸ¤– Assistant: The largest object is the blue square at
   [0.18, -0.10] with an area of 25 square centimeters.
```

```
You: What objects are on the left side?

ðŸ”§ Calling tool: get_detected_objects(
     location="left next to",
     coordinate=[0.25, 0.0]
   )
âœ“ Result: Found 2 objects on left side

ðŸ¤– Assistant: On the left side I found:
   - Red cube at [0.20, 0.10]
   - Pen at [0.18, -0.03]
```

---

### Safe Placement

```
You: Find a safe place to put this object

ðŸ”§ Calling tool: get_largest_free_space_with_center
âœ“ Result: area=0.0050 mÂ², center=[0.25, -0.04]

ðŸ”§ Calling tool: place_object([0.25, -0.04], None)
âœ“ Result: Successfully placed

ðŸ¤– Assistant: I've placed the object in the largest free space
   at [0.25, -0.04] (50 cmÂ² available).
```

---

## Object Manipulation

### Sorting by Size

```
You: Sort all objects by size from smallest to largest in a line

ðŸ”§ Calling tool: get_detected_objects_sorted(ascending=True)
âœ“ Result: Sorted 3 objects by size

ðŸ”§ Calling tool: pick_place_object (object 1)
   Arguments: {"object_name": "pen", ...}
âœ“ Result: Placed smallest object

ðŸ”§ Calling tool: pick_place_object (object 2)
   Arguments: {"object_name": "pencil", ...}
âœ“ Result: Placed medium object

ðŸ”§ Calling tool: pick_place_object (object 3)
   Arguments: {"object_name": "cube", ...}
âœ“ Result: Placed largest object

ðŸ¤– Assistant: Done! I've sorted all objects by size in a horizontal
   line:
   - Smallest: pen at [0.15, -0.05]
   - Medium: pencil at [0.15, 0.03]
   - Largest: cube at [0.15, 0.11]
```

---

### Color-Based Grouping

```
You: Group objects by color: red on left, blue on right

ðŸ”§ Calling tool: get_detected_objects
âœ“ Result: Found 4 objects

ðŸ”§ Calling tool: pick_place_object (red cube)
âœ“ Result: Moved to left side

ðŸ”§ Calling tool: pick_place_object (blue square)
âœ“ Result: Moved to right side

ðŸ¤– Assistant: Objects are now grouped by color:
   - Left side (red): red cube at [0.20, 0.06]
   - Right side (blue): blue square at [0.20, -0.06]
```

---

### Stacking Objects

```
You: Stack the small cube on top of the large cube

ðŸ”§ Calling tool: get_detected_objects(label="cube")
âœ“ Result: Found 2 cubes

ðŸ”§ Calling tool: pick_place_object
   Arguments: {
     "object_name": "small cube",
     "pick_coordinate": [0.16, 0.05],
     "place_coordinate": [0.22, 0.10],
     "location": "on top of"
   }
âœ“ Result: Successfully stacked

ðŸ¤– Assistant: Perfect! I've stacked the small cube on top of
   the large cube at [0.22, 0.10].
```

---

## Spatial Reasoning

### Triangle Pattern

```
You: Arrange objects in a triangle

ðŸ”§ Calling tool: get_detected_objects
âœ“ Result: Found 3 objects

ðŸ”§ Calling tool: pick_place_object (object 1)
   â†’ Top vertex: [0.20, 0.00]
âœ“ Result: Placed

ðŸ”§ Calling tool: pick_place_object (object 2)
   â†’ Bottom right: [0.28, -0.06]
âœ“ Result: Placed

ðŸ”§ Calling tool: pick_place_object (object 3)
   â†’ Bottom left: [0.28, 0.06]
âœ“ Result: Placed

ðŸ¤– Assistant: Done! Objects arranged in triangle:
        â—‹ [0.20, 0.00]
       / \
      /   \
     â—‹â”€â”€â”€â”€â”€â—‹
   [0.28,  [0.28,
    0.06]  -0.06]
```

---

### Distance-Based Queries

```
You: What's the closest object to [0.2, 0.0]?

ðŸ”§ Calling tool: get_detected_objects(
     location="close to",
     coordinate=[0.2, 0.0]
   )
âœ“ Result: Found pencil at [0.20, 0.02]

ðŸ¤– Assistant: The pencil at [0.20, 0.02] is closest,
   only 2 centimeters away from [0.2, 0.0].
```

---

### Boundary-Aware Placement

```
You: Place objects at the corners of the workspace

ðŸ”§ Calling tool: get_workspace_coordinate_from_point
   ("niryo_ws", "upper left corner")
âœ“ Result: [0.337, 0.087]

ðŸ”§ Calling tool: get_workspace_coordinate_from_point
   ("niryo_ws", "upper right corner")
âœ“ Result: [0.337, -0.087]

ðŸ”§ Calling tool: pick_place_object (4 times)
âœ“ Result: Placed all objects at corners

ðŸ¤– Assistant: Objects placed at workspace corners:
   - Upper left: [0.337, 0.087]
   - Upper right: [0.337, -0.087]
   - Lower left: [0.163, 0.087]
   - Lower right: [0.163, -0.087]
```

---

## Complex Workflows

### Multi-Step Task

```
You: Execute: 1) Find the pencil 2) Move it to center 3) Find
     largest object 4) Place it right of pencil 5) Report positions

ðŸ”§ Calling tool: get_detected_objects(label="pencil")
âœ“ Result: Pencil at [0.15, -0.05]

ðŸ”§ Calling tool: get_workspace_coordinate_from_point
   ("niryo_ws", "center point")
âœ“ Result: [0.25, 0.0]

ðŸ”§ Calling tool: pick_place_object
   â†’ Move pencil to center
âœ“ Result: Placed at [0.25, 0.0]

ðŸ”§ Calling tool: get_largest_detected_object
âœ“ Result: Red cube at [0.20, 0.10]

ðŸ”§ Calling tool: pick_place_object
   Arguments: {
     "place_coordinate": [0.25, 0.0],
     "location": "right next to"
   }
âœ“ Result: Placed right of pencil

ðŸ”§ Calling tool: get_detected_objects
âœ“ Result: Updated positions

ðŸ¤– Assistant: Task completed! Final positions:
   - Pencil: [0.25, 0.0] (center)
   - Red cube: [0.25, -0.04] (right of pencil)
```

---

### Conditional Logic

```
You: If there are more than 3 objects, arrange in grid.
     Otherwise, arrange in line.

ðŸ”§ Calling tool: get_detected_objects
âœ“ Result: Found 4 objects

ðŸ¤– Assistant: Found 4 objects (more than 3), arranging in 2Ã—2 grid...

ðŸ”§ Calling tool: pick_place_object (4 times)
   Grid positions:
   [0.18, -0.04] [0.18, 0.04]
   [0.26, -0.04] [0.26, 0.04]
âœ“ Result: All objects arranged

ðŸ¤– Assistant: Grid arrangement complete:
   â—‹  â—‹  [0.18, -0.04] [0.18, 0.04]
   â—‹  â—‹  [0.26, -0.04] [0.26, 0.04]
```

---

### Error Recovery

```
You: Try to pick the 'diamond'. If not found, pick any object instead.

ðŸ”§ Calling tool: get_detected_objects(label="diamond")
âœ“ Result: No object with label 'diamond' found

ðŸ”§ Calling tool: speak("Diamond not found. Picking alternative object.")
âœ“ Result: Speaking...

ðŸ”§ Calling tool: get_detected_objects
âœ“ Result: Found 3 objects

ðŸ”§ Calling tool: pick_object("pencil", [0.15, -0.05])
âœ“ Result: Picked pencil as alternative

ðŸ¤– Assistant: I couldn't find a diamond, so I picked up the
   pencil instead as an alternative.
```

---

## Advanced Patterns

### Batch Processing

```
You: Move all small objects (< 20 cmÂ²) to the left side

ðŸ”§ Calling tool: get_detected_objects
âœ“ Result: Found 4 objects

ðŸ¤– Assistant: Filtering objects under 20 cmÂ²...
   Found 2 small objects: pen (16.8 cmÂ²), pencil (18 cmÂ²)

ðŸ”§ Calling tool: pick_place_object (pen)
   â†’ Target: [0.18, -0.06]
âœ“ Result: Placed

ðŸ”§ Calling tool: pick_place_object (pencil)
   â†’ Target: [0.18, -0.01]
âœ“ Result: Placed

ðŸ”§ Calling tool: speak("Moved 2 small objects to the left")
âœ“ Result: Speaking...

ðŸ¤– Assistant: Done! Moved 2 small objects to the left side:
   - Pen: [0.18, -0.06]
   - Pencil: [0.18, -0.01]
```

---

### Push Operations

```
You: If the object is too large to pick, push it instead

ðŸ”§ Calling tool: get_largest_detected_object
âœ“ Result: Large box at [0.25, 0.05], width: 8cm

ðŸ¤– Assistant: Object width (8cm) exceeds gripper limit (5cm).
   Using push operation...

ðŸ”§ Calling tool: speak("Object too large to grip. Using push.")
âœ“ Result: Speaking...

ðŸ”§ Calling tool: push_object
   Arguments: {
     "object_name": "large box",
     "push_coordinate": [0.25, 0.05],
     "direction": "right",
     "distance": 50.0
   }
âœ“ Result: Pushed 50mm to the right

ðŸ¤– Assistant: Successfully pushed the large box 5cm to the right.
   New position: [0.25, 0.0]
```

---

### Dynamic Workspace Adaptation

```
You: Organize workspace: densely packed objects to right,
     spread out objects to left

ðŸ”§ Calling tool: get_detected_objects
âœ“ Result: Found 5 objects

ðŸ¤– Assistant: Analyzing object density...
   - Dense cluster (3 objects): right side
   - Sparse objects (2 objects): left side

ðŸ”§ Calling tool: pick_place_object (3 times for dense)
   â†’ Right positions: [0.28, -0.08], [0.28, -0.04], [0.28, 0.0]
âœ“ Result: Dense objects positioned

ðŸ”§ Calling tool: pick_place_object (2 times for sparse)
   â†’ Left positions: [0.18, -0.02], [0.18, 0.06]
âœ“ Result: Sparse objects positioned

ðŸ¤– Assistant: Workspace organized:
   - Left (sparse): 2 objects with 8cm spacing
   - Right (dense): 3 objects with 4cm spacing
```

---

## Tips and Best Practices

### 1. Always Detect Before Manipulating

```
âœ… Good:
You: What objects do you see?
     [Wait for response]
You: Pick up the pencil

ðŸ”§ Uses fresh coordinates from detection

âŒ Bad:
You: Pick up the pencil at [0.15, -0.05]

âš ï¸  Coordinates might be stale if object moved
```

---

### 2. Use Exact Label Matching

```
âœ… Good:
ðŸ”§ get_detected_objects
âœ“ Result: Found "pencil" (lowercase)

ðŸ”§ pick_object("pencil", ...)  â† Exact match

âŒ Bad:
ðŸ”§ pick_object("Pencil", ...)  â† Wrong case
ðŸ”§ pick_object("pen", ...)     â† Wrong object
```

---

### 3. Check for Success

```
âœ… Good:
You: Pick up the pencil
     [Wait for confirmation]
You: Did that work?

ðŸ”§ Calling tool: get_detected_objects(label="pencil")
âœ“ Result: Pencil position changed â† Success!

âŒ Bad:
You: Pick up pencil. Move cube. Stack items.
     [No verification between steps]
```

---

### 4. Use Safe Placement

```
âœ… Good:
You: Place object in a safe location

ðŸ”§ get_largest_free_space_with_center
âœ“ Result: area=0.0045 mÂ², center=[0.24, -0.03]

ðŸ”§ place_object([0.24, -0.03], None)
âœ“ Result: No collisions

âŒ Risky:
You: Place object at [0.25, 0.0]

âš ï¸  Might collide with existing objects
```

---

### 5. Provide User Feedback

```
âœ… Good:
ðŸ”§ speak("Scanning workspace...")
ðŸ”§ get_detected_objects
ðŸ”§ speak("Found 3 objects")
ðŸ”§ pick_place_object
ðŸ”§ speak("Task completed successfully")

âŒ Bad:
ðŸ”§ get_detected_objects
ðŸ”§ pick_place_object
[Silent operation, user uncertain]
```

---

### 6. Handle Workspace Bounds

```
âœ… Good:
ðŸ”§ get_workspace_coordinate_from_point("niryo_ws", "upper left")
âœ“ Result: [0.337, 0.087] â† Valid bounds

ðŸ”§ Ensure target within: X=[0.163, 0.337], Y=[-0.087, 0.087]

âŒ Bad:
ðŸ”§ place_object([0.50, 0.20], None)
âœ— Error: Coordinates out of workspace bounds
```

---

### 7. Use Relative Placement

```
âœ… Good - Adaptive:
ðŸ”§ pick_place_object(
     ...,
     place_coordinate=[0.22, 0.10],
     location="right next to"
   )
âœ“ Robot calculates exact position with safe spacing

âŒ Less Flexible - Manual:
target_y = 0.10 - 0.04  # Manual offset
ðŸ”§ pick_place_object(..., [0.22, 0.06], None)
âš ï¸  Fixed spacing might not be optimal
```

---

## Running the Examples

### Interactive Mode

```bash
python client/fastmcp_universal_client.py

You: Sort all objects by size
You: Arrange them in a triangle
You: Tell me what you see
```

---

### Single Command Mode

```bash
# Run one example
python client/fastmcp_universal_client.py \
  --command "Sort objects by size"

# Batch script
for cmd in "Scan workspace" "Sort by size" "Create triangle"; do
  python client/fastmcp_universal_client.py --command "$cmd"
  sleep 2
done
```

---

### Web GUI

```bash
python robot_gui/mcp_app.py --robot niryo

# Use voice commands or text input
# See live camera feed
# Get visual feedback
```

---

### Example Scripts

```bash
# Run specific example
python examples/universal_examples.py workspace_scan

# Run all examples
python examples/universal_examples.py all

# Compare LLM providers
python examples/universal_examples.py compare_providers
```

---

## Common Natural Language Commands

```
"What objects do you see?"
"Pick up the pencil"
"Move the red cube next to the blue square"
"Sort all objects by size"
"Arrange objects in a triangle"
"What's the largest object?"
"Place the smallest object in the center"
"Find a safe place to put this"
"Stack the small cube on the large cube"
"Push the large box 5cm to the right"
"Group objects by color"
"Is there anything near [0.2, 0.0]?"
```

---

For more information:
- [API Reference](api.md) - Complete tool documentation
- [Setup Guide](mcp_setup_guide.md) - Installation and configuration
- [Troubleshooting](troubleshooting.md) - Common issues and solutions
